---
title: "coding_michael"
author: "Eliane Mitchell"
date: "3/19/2021"
output: html_document

---
## Step 1: Load Packages

```{r}
library(tidyverse)
library("xlsx")
library(tm)
library(stringr)
library(glue)
install.packages("readxl")
slibrary(tidytext)
```

## Step 2: Load in data

```{r }
setwd("~/Desktop/R Folder")

data <- xlsx::read.xlsx("/Users/eliane/Desktop/R Folder/coding_data_two.xlsx", sheetIndex = 1, endRow=352) # increase endRow if you want to see how the NLP adds rows without Katie

keys <- xlsx::read.xlsx("/Users/eliane/Desktop/R Folder/coding_data_two.xlsx", sheetIndex = 2, endRow=40) # increase endRow if you want to see how the NLP adds rows without Katie

```

## Step 3: Clean up dataframe with responses and clean up responses themselves

```{r}

dat <- sapply(data, as.character)
colnames(dat) <- dat[1, ]  
dat <- as.data.frame(dat[-1,])
dat <- dat[,-c(2,4)]

prep_section <- dat %>% mutate(
  response_lower = tolower(Response), 
  response_lower = str_replace_all(response_lower, "[[:punct:]]", ""), 
  response_lower = str_squish(response_lower) 
)

# Adds space to front and end of string. This is so that, when matching patterns, the first and last words of a string are recognized
prep_section$response_lower <- str_pad(prep_section$response_lower, 
                                  str_length(prep_section$response_lower) + 2,
                                  "both", " ")

# Choose rows to isolate (can be 1-25, 26-50, 51-75, 76-100, 1-100, 101-150, 1-300, etc.)
#prep_section <- prep_section[c(1:349), ]
prep_section <- prep_section[c(1:349), ]


```

## Step 4: Clean up dataframe with key words. Clean up spacing, convert to lower case

```{r}
keys <- keys[1:32,] 
keys_data <- keys %>% rename(key_words=Key.Words) %>% mutate(key_words = str_squish(key_words)) 
keys_data$key_words <- tolower(keys_data$key_words) 
```

## Step 5: Add two columns. One with the matches that the NLP identifies ("NLP_heads"); the other with the matches that Katie identified

```{r}

# Apply function to each row of the selected prep_section that identifies NLP matches. If the headline we are looking to match is 22 or 26, then add the "NOT" crosscheck

prep_section$NLP_heads <- sapply(prep_section$response_lower, FUN = function(x){ 
  matches <- c("") 
  for (row in 1:nrow(keys_data)) { 
    string_head <- keys_data[row, "key_words"] 
    
    if(row == 6) {
      if(isTRUE(grepl(string_head, x)) & isTRUE(!grepl("saved by", x))) {
        matches <- paste(matches, row)
        next
      } else {
        matches <- paste(matches, "")
        next
      } }
    
    if(row == 21) {
      if(isTRUE(grepl(string_head, x)) & isTRUE(!grepl("1973", x))) {
        matches <- paste(matches, row)
        next
      } else {
        matches <- paste(matches, "")
        next
      } }
    
    if(row == 22) { 
      if(isTRUE(grepl(string_head, x)) & isTRUE(!grepl("nixon", x)) & isTRUE(!grepl("^high", x))) {
        matches <- paste(matches, row)
        next
      } else {
        matches <- paste(matches, "")
        next
      } }
    
    if(row == 23) { 
      if(isTRUE(grepl(string_head, x)) & isTRUE(grepl("nixon", x))) {
        matches <- paste(matches, row)
        next
      } else {
        matches <- paste(matches, "")
        next
      } }
    
    if(row == 24) { 
      if(isTRUE(grepl(string_head, x)) & isTRUE(grepl("tax.*cut | tax cuts? | cutting tax | tax breaks? | tax refunds? | tas plan | taxes", x))) {
        matches <- paste(matches, row)
        next
      } else {
        matches <- paste(matches, "")
        next
      } }
    
    if(row == 28) {
      if(isTRUE(grepl(string_head, x)) & isTRUE(grepl("tarrifs? | tarriffs? | tariffs? | tarifs? | trade ", x))) {
        matches <- paste(matches, row)
        next
      } else {
        matches <- paste(matches, "")
        next
      } }
    
    if(isTRUE(grepl(string_head, x))) {
      matches <- paste(matches, row)
    } else {
      matches <- paste(matches, "") } } 
  
  matches } )

# Creates column with a list of the headlines that Katie identified. Also (optionally) adds columns with the headlines that the NLP identified, disaggregated (e_#)

section <- prep_section %>% 
  mutate(unite(across(everything(), 
                      ~ ifelse( . == "1", cur_column(), NA)), 
               na.rm = T, col = "manual_heads")) %>%
  mutate(across(3:34, .names = "e_{.col}" )) %>%
  rename_with(~str_c("k_", .), c(3:34))

```

## Step 6: Change NAs (blanks) to 0

```{r}

index <- is.na(section)
section[index] <- 0
#section[section=="?"]<- 0

```

## Step 7: (Pretty much optional) Assigns 0 or 1 to e columns where the NLP identified a headline. Though we use this later to see which headlines the NLP missed or added 

```{r}

for (i in 1:nrow(section)) {
  response <- section[i, "response_lower"]
  for (row in 1:nrow(keys_data)) {
    headline <- keys_data[row, "key_words"]
    col <- gsub(" ", "", paste("e_", row))
    
    if(row == 6) {
      if(isTRUE(grepl(headline, response)) & isTRUE(!grepl("saved by", response))) {
        section[i, col] = 1
        next
      } else {
        section[i, col] = 0
        next
      } }
    
    if(row == 21) {
      if(isTRUE(grepl(headline, response)) & isTRUE(!grepl("1973", response))) {
        section[i, col] = 1
        next
      } else {
        section[i, col] = 0
        next
      } }
    
    if(row == 22) { 
      if(isTRUE(grepl(headline, response)) & isTRUE(!grepl("nixon", response)) & isTRUE(!grepl("^high", response))) {
        section[i, col] = 1
        next
      } else {
        section[i, col] = 0
        next
      } }
    
    if(row == 23) { 
      if(isTRUE(grepl(headline, response)) & isTRUE(grepl("nixon", response))) {
        section[i, col] = 1
        next
      } else {
        section[i, col] = 0
        next
      } }
    
    if(row == 24) { 
      if(isTRUE(grepl(headline, response)) & isTRUE(grepl("tax.*cut | tax cuts? | cutting tax | tax breaks? | tax refunds? | tas plan | taxes", response))) {
        section[i, col] = 1
        next
      } else {
        section[i, col] = 0
        next
      } }
    
    if(row == 26) {
      if(isTRUE(grepl(headline, response)) & isTRUE(grepl("tarrifs? | tarriffs? | tariffs? | tarifs? | trade ", response))) {
        section[i, col] = 1
        next
      } else {
        section[i, col] = 0
        next
      } }
    
    if(isTRUE(grepl(headline, response))) {
      section[i, col] = 1
    } else {
      section[i, col] = 0 
    }
  }
} 
```

## Step 8: Create columns containing number of hits and not matches 

```{r}

section[3:34] <- lapply(section[3:34], as.numeric)
section[39:70] <- lapply(section[39:70], as.numeric)

section$hits <- NA_integer_
section$not_matches <- NA_integer_

suffixes <- 1:32
for (i in 1:nrow(section)) {
  hits <- vector("logical", length(suffixes))
  names(hits) <- suffixes
  not_matches <- vector("logical", length(suffixes))
  names(not_matches) <- suffixes
   for (j in suffixes) {
     hits[[j]] <- (section[[glue("e_{j}")]][i] & section[[glue("k_{j}")]][i]) == 1
     not_matches[[j]] <- section[[glue("e_{j}")]][i] != section[[glue("k_{j}")]][i]
   }
  section$hits[i] <- sum(hits, na.rm=T)
  section$not_matches[i] <- sum(not_matches, na.rm = T)
}

# Create columns for percent accuracy, etc.

section2 <- section %>% mutate( 
  total_hits_nm = hits + not_matches,
  percent_accuracy = hits / total_hits_nm, 
  manual_heads = str_replace_all(
    manual_heads, "[\\s_]", " "),
  NLP_heads = str_squish(NLP_heads))

# Rearrange columns so more readable (I'm sure there's a way to NOT hard code this)

section3 <- section2[, c(1, 36, 37, 38, 71, 72, 73, 74, 3, 39, 4, 40, 5, 41, 6, 42, 7, 43, 8, 44, 9, 45, 10, 46, 11, 47, 12, 48, 13, 49, 14, 50, 15, 51, 16, 52, 17, 53, 18, 54, 19, 55, 20, 56, 21, 57, 22, 58, 23, 59, 24, 60, 25, 61, 26, 62, 27, 63, 28, 64, 29, 65, 30, 66, 31, 67, 32, 68, 33, 69, 34, 70)] 

```

## Step 9: Create columns that show whether the NLP added or missed a headline

```{r}
section3$added <- ""
section3$missing <- ""

suffixes <- 1:32

for (i in 1:nrow(section3)) {
  added <- ""
  missing <- ""
  empty <- ""
  for (j in suffixes) {
    
    if (isTRUE(section3[[glue("e_{j}")]][i] > section3[[glue("k_{j}")]][i])) {
      added <- paste(added, j)
    } else if (isTRUE(section3[[glue("e_{j}")]][i] < section3[[glue("k_{j}")]][i])) {
      missing <- paste(missing, j) 
    } else {
      NULL
    }
    section3$added[[i]] <- added
    section3$missing[[i]] <- missing
  }
}

section3 <- section3[, c(1:8, 73, 74, 9:72)]
```


```{r}

View(section3 %>% select(response_lower, NLP_heads, manual_heads, added, missing))

```

## Find overall accuracy

```{r}

mean(section3$percent_accuracy, na.rm = T)
# currently, as it stands: 70% for second batch
```

## Tools for easily finding what headlines are added or are missing, and filtering out the rows where that headline is missing or added

```{r}
# To show the most common missing or added headlines. word = headline # ; n = frequency 
View(section3 %>% unnest_tokens(word, missing) %>% count(word, sort=TRUE))
View(section3 %>% unnest_tokens(word, added) %>% count(word, sort=TRUE))

# To filter the rows with a headline missing
filtered <- filter(section3, grepl("26", missing)) # change the # to see rows where the headline is missing
View(filtered %>% select(response_lower, NLP_heads, manual_heads, added, missing))

filtered <- filter(section3, grepl("6 ", added)) # change the # to see rows where the headline was added
View(filtered %>% select(response_lower, NLP_heads, manual_heads, added, missing))

```

